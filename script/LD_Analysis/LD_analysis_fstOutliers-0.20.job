#!/bin/bash
#PBS -l mem=62gb,nodes=1:ppn=24,walltime=48:00:00
#PBS -m abe
#PBS -M liux1299@umn.edu
#PBS -q lab

set -e
set -o pipefail

module load R/3.4.3
module load python2/2.7.8 # Tom's VCF_To_Htable-TK.py script runs in Python 2
module load vcflib_ML/1.0.0
module load parallel

#   Usage message:
#       This script performs LD analysis on 100Kb windows around fst outlier SNPs from Environmental
#       Associations project fstOutlier analysis. This script pulls together all parts of the analysis
#       performed by multiple scripts.
#       Please fill out user provided argument fields and submit script as job.


#   User provided arguments
#   Where is the directory containing this script?
#   Make sure all scripts needed are in same directory as this script
SCRIPT_DIR=/home/morrellp/liux1299/GitHub/Env_Assoc/script/LD_Analysis
#   List of sorted fst oulier SNP names based on Ana's fstOutlier analysis
FST_OUTLIER_SNPS=/home/morrellp/liux1299/Projects/Land_Env_Assoc/Analysis/LD_Analysis/data/combinedFstOutliers_sorted_uniq.txt
#   Need sorted_all_9k_masked_90idt.vcf
VCF_9K=/home/morrellp/liux1299/GitHub/9k_BOPA_SNP/BOPA_9k_vcf_Morex_refv1/sorted_all_9k_masked_90idt.vcf
#   VCF file from dataset we are interested in (i.e. OnlyLandrace_Barley_NAM_Parents_Final_renamed.vcf)
MAIN_VCF=/panfs/roc/groups/9/morrellp/shared/Projects/Land_Env_Assoc/Analysis/LD_Analysis/data/NAM_landraces_100_DP2_renamed_2018-05-21.vcf
#   window size (bp) upstream/downstream of SNP for extract_BED.R
BP=100000
#   Minor Allele Frequency threshold to use for VCF to Htable conversion (i.e. 0.01 for 1% MAF)
MAF=0.01
#   Missing data threshold to use for filtering (i.e. 0.15 for 15% missing data)
P_MISSING=0.20
#   What prefix do we want to use for our output files?
PREFIX=ld_Barley_NAM_200Kb_0.20
#   Where is our output directory?
OUT_DIR=/home/morrellp/liux1299/Shared/Projects/Land_Env_Assoc/Analysis/LD_Analysis/results/fst_outlier_snps_200Kb/0.20_threshold

#   Pull functions from LD_analysis_fstOutliers.sh script
source "${SCRIPT_DIR}"/LD_analysis_fstOutliers.sh

#   Start analysis
#   Number of Individuals we have data for (i.e. WBDC)
N_INDIVIDUALS=$(grep "#CHROM" "${MAIN_VCF}" | tr '\t' '\n' | tail -n +10 | wc -l)
echo "Number of individuals in data:"
echo "${N_INDIVIDUALS}"
#   Save the filepaths to scripts that we need
cd "${SCRIPT_DIR}"
#   extract_BED.R script creates a BED file that is 50Kb upstream/downstream of
#       the fst outlier SNP
EXTRACT_BED=$(find $(pwd) -name extract_BED.R)
#   VCF_To_Htable-TK.py script reads in a VCF file and outputs a fake Hudson table
#       This script filters sites based on Minor Allele Frequency (MAF) threshold
VCF_TO_HTABLE=$(find $(pwd) -name VCF_To_Htable-TK.py)
#   transpose_data.R script transposes Htable created from VCF_To_Htable-TK.py
TRANSPOSE_DATA=$(find $(pwd) -name transpose_data.R)
#   LD_data_prep.sh script prepares genotyping data for LDheatmap.R script
#       and prevents errors that occur due to samples/markers mismatch between
#       SNP_BAC.txt file and genotype matrix
LD_DATA_PREP=$(find $(pwd) -name LD_data_prep.sh)
EXTRACTION_SNPS=$(find $(pwd) -name extraction_SNPs.pl)
#   LDheatmap.R script generates r2 and D' heatmap plots
LD_HEATMAP=$(find $(pwd) -name LDheatmap.R)

#   Build our SNP list but skip 1st header line
SNP_LIST=($(cat "${FST_OUTLIER_SNPS}" | sort -uV))
#   Number of fstOutlier SNPs (GSS) in array
GSS_LEN=${#SNP_LIST[@]}
echo "Number of fst outlier SNPs in array:"
echo ${GSS_LEN}

#   Check if out directory exists, if not make it
mkdir -p "${OUT_DIR}"

echo "Extracting fst outlier SNPs from 9k_masked_90idt.vcf file..."
#   Check if out directory exists, if not make directory
mkdir -p "${OUT_DIR}/extracted_sig_snps_vcf"
#   Running extractSNPs will output the following file:
#       1) prefix_9k_masked_90idt.vcf file(s) contains fst outlier SNPs from fstOutlier analysis
#       2) sig_snp_not_in9k.txt file contains fst outlier SNPs that don't exist in the sorted_all_9k_masked_90idt.vcf file
#   We start with a list of fstOutlier fst outlier SNP names,
#   pull those SNPs from the sorted_all_9k_masked_90idt.vcf file
#   to create VCF files containing 1 fst outlier SNP/VCF file
touch "${OUT_DIR}/extracted_sig_snps_vcf/sig_snp_not_in_9k.txt"
parallel extractSNPs {} "${VCF_9K}" "${PREFIX}" "${OUT_DIR}/extracted_sig_snps_vcf" ::: "${SNP_LIST[@]}"
echo "Done extracting fst outlier SNPs."

echo "Removing non-existent SNP from bash array..."
#   Check if out directory exists, if not make directory
mkdir -p "${OUT_DIR}/temp"
#   Filter out and remove SNPs that don't exist from bash array
DELETE=($(cat "${OUT_DIR}/extracted_sig_snps_vcf/sig_snp_not_in_9k.txt"))
filterSNPs "${DELETE}" "${SNP_LIST}" "${OUT_DIR}"

echo "Extracting all SNPs that fall within window defined..."
#   Check if out directory exists, if not make directory
mkdir -p "${OUT_DIR}/extracted_window"
#   Running extractWin will output the following files:
#       1) BED file(s) of n Kb upstream/downstream of SNP (should have 1 line within file)
#       2) intersect.vcf file(s) that contains all SNPs that fall within BED file interval
#   We start with our prefix_9k_masked_90idt.vcf files
#   and create a BED file interval n bp upstream/downstream of fst outlier SNP.
#   Then we use vcfintersect for BED file we created and our VCF file of
#   interest (i.e. OnlyLandrace_biallelic_Barley_NAM_Parents_Final_renamed.vcf)
#   to pull down all SNPs that fall within our BED file interval.
parallel extractWin {} "${EXTRACT_BED}" "${BP}" "${OUT_DIR}/extracted_sig_snps_vcf/${PREFIX}_{}_9k_masked_90idt.vcf" "${MAIN_VCF}" "${PREFIX}" "${OUT_DIR}/extracted_window" ::: "${SNP_LIST_FILT[@]}"
echo "Done extracting SNPs within window."

#   Filter out intersect.vcf files that are empty by removing SNP name from bash array
INTERSECT_VCF=($(find "${OUT_DIR}"/extracted_window/*.vcf))
SNP_INT_VCF=()
for i in "${INTERSECT_VCF[@]}"
do
    #   redirect filename into wc to get integer only
    num_lines=$(wc -l < ${i})
    #   If there is only 1 line in the file (the header line),
    #   save the full filepath to file
    if [ "${num_lines}" -eq "1" ]
    then
        basename ${i} >> "${OUT_DIR}/extracted_window/empty_intersect_vcf.txt"
        basename ${i} | sed -e s/^${PREFIX}_// -e s/_intersect.vcf// >> "${OUT_DIR}/extracted_window/empty_intersect_vcf_SNPnamesOnly.txt"
    else
        #   Extract only the SNP name from filename using sed substitution
        #   to remove prefix and suffix.
        #   This works because ${PREFIX} is defined as variable at top of script
        #   and extractWin function uses ${PREFIX} in output file names.
        #   The suffix of extractWin output files is always "_intersect.vcf"
        SNP=$(basename ${i} | sed -e s/^${PREFIX}_// -e s/_intersect.vcf//)
        #   Add SNPs we want to use in downstream functions to new array
        SNP_INT_VCF+=(${SNP})
    fi
done

echo "Converting VCF to fake Hudson table..."
#   Check if out directory exists, if not make directory
mkdir -p "${OUT_DIR}/Htable"
#   Running vcfToHtable will filter on MAF and output the following files:
#       1) Htable_sorted.txt file(s) which is the VCF converted to fake Hudson table format
#       2) Htable_sorted_transposed.txt file(s) which outputs SNPs as rows and individuals as columns
#       3) Htable_sorted_transposed_noX.txt which removes "X" in marker names
#   We start with our intersect.vcf file(s) and convert them to a fake Hudson table format
#   and filter based on MAF (specified above under user provided argument).
#   The output will have marker names (i.e. 11_20909) as columns and sample naems (i.e. WBDC-025) as row names.
parallel vcfToHtable {} "${VCF_TO_HTABLE}" "${MAF}" "${TRANSPOSE_DATA}" "${PREFIX}" "${OUT_DIR}" ::: "${SNP_INT_VCF[@]}"
echo "Done converting VCF to fake Hudson table."

echo "Creating SNP_BAC.txt file..."
#   Check if out directory exists, if not make directory
mkdir -p "${OUT_DIR}/snp_bac"
#   Running makeSnpBac will output file(s) that contain 3 columns:
#       1) Query_SNP which is the SNP name
#       2) PhysPos which is the physical position
#       3) Chr which is the chromosome
#   Output files are sorted by physical position (column 2)
parallel makeSnpBac {} "${PREFIX}" "${OUT_DIR}" ::: "${SNP_INT_VCF[@]}"
echo "Done creating SNP_BAC.txt."

echo "Preparing data for LD analysis..."
#   Check if out directory exists, if not make directory
mkdir -p "${OUT_DIR}/ld_data_prep"
#   Running ldDataPrep will output the following files:
#       1) sorted_EXISTS.txt which contains SNPs that exist in our genotyping data
#       2) NOT_EXISTS.txt is a list of SNPs that do not exist in our genotyping data but exist in our SNP_BAC.txt file
#       3) SNP_BAC_filtered.txt has all non-existent SNPs removed so it doesn't cause errors when using LDheatmap command in R
parallel ldDataPrep {} "${LD_DATA_PREP}" "${EXTRACTION_SNPS}" "${OUT_DIR}"/Htable/"${PREFIX}"_{}_intersect_Htable_sorted_transposed_noX.txt "${PREFIX}" "${OUT_DIR}" ::: "${SNP_INT_VCF[@]}"
echo "Done preparing data."

echo "Running LD analysis..."
mkdir -p "${OUT_DIR}/ld_results/ldheatmap_error_snps"
#   Running ldHeatMap will output the following files:
#       1) SNP_info-empty_cols.csv is a list of samples with empty columns
#       2) SNP_info-failed_snps.csv is a list of incompatible genotype columns
#       3) SNP_info-missing_data_cols.csv is a list of SNPs that had greater than n% missing data
#           (missing data threshold is defined under user provided arguments section)
#       4) compatibleSnps.txt is a matrix of SNPs that will be used for LDheatmap analyses
#       5) HM_r2.pdf is a heatmap for r2 calculation
#       6) HM_Dprime.pdf is a heatmap for D' calculation
#       7) HM_r2.txt is a matrix of r2 values used in heatmap
#       8) HM_Dprime.txt is a matrix of D' values used in heatmap
parallel ldHeatMap {} "${LD_HEATMAP}" "${N_INDIVIDUALS}" "${P_MISSING}" "${OUT_DIR}" ::: "${SNP_INT_VCF[@]}"
echo "Done with all analyses."
